Similarity-based approaches to machine learning come from the idea that the best way to make a predictions is to simply look at what has worked well in the past and predict the same thing again. The fundamental concepts required to build a system based on this idea are **feature spaces** and **measures of similarity**, and these are covered in the fundamentals section of this chapter. These concepts allow us to understand the standard approach to building similarity-based models: the **nearest neighbor algorithm**. After covering the standard algorithm, we then look at extensions and variations that allow us to handle noisy data (the *k* **nearest neighbor**, or *k***-NN**, algorithm), to make predictions more efficiently (*k-d* **trees**), to predict continuous targets, and to handle different kinds of descriptive features with varying **measures of similarity**. We also take the opportunity to introduce the use of **data normalization** and **feature selection** in the context of similarity-based learning. These techniques are generally applicable to all machine learning algorithms but are especially important when similarity-based approaches are used.

